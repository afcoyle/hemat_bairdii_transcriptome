---
title: "9_2_merging_jensen_files"
author: "Aidan Coyle"
date: "8/26/2021"
output: html_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Introduction

Earlier, we downloaded a series of files obtained from Pam Jensen, formerly of the Alaska Department of Fish and Game. These files describe a large number of samples that were taken of crab from the early 2000s until 2019. The samples, which are predominantly in deep 96-well plates, were also sent to the Roberts Lab from Pam. We documented all plates we obtained, and in this script will cross-reference the file of obtained plates with Pam's files, to create a full inventory of all samples.


```{r libraries, message=FALSE, warning=FALSE}
# Add all required libraries here
list.of.packages <- c("tidyverse", "RODBC", "readxl", "lubridate")
# Get names of all required packages that aren't installed
new.packages <- list.of.packages[!(list.of.packages %in% installed.packages()[, "Package"])]
# Install all new packages
if(length(new.packages)) install.packages(new.packages)


# Load all required libraries
lapply(list.of.packages, FUN = function(X) {
  do.call("require", list(X))
})
```

Now we'll start by importing our Access database

## Reading In Data (Access, -2013)

```{r}

# Set up driver info and database path
driver_info <- "Driver={Microsoft Access Driver (*.mdb, *.accdb)};"

db_path <- "../data/jensen_archived_samples/jensen_data/Hemato_samples/databases_thru_2013/FRP_Database_ReadOnly.accdb"

access_path <- paste0(driver_info, "DBQ=", db_path)

# Establish connection
channel <- odbcDriverConnect(access_path)

# Import collection data table
collection.dat <- sqlQuery(channel,
                       "SELECT * FROM [tbl_ALL_New_Collection_Results] ORDER BY [SPNO];")

plate.dat <- sqlQuery(channel,
                      "SELECT * FROM [tbl_Plates] ORDER BY [SPNO];")


samp.dat <- sqlQuery(channel,
                     "SELECT * FROM [tbl_Samples] ORDER BY [SPNO];")

comments.dat <- sqlQuery(channel,
                         "SELECT * FROM [tbl_COMMENTS_Collection_Sample] ORDER BY [SPNO];")
```

Alright, we've got our tables imported.

Looks like SPNO is used to identify the individual crab, while SPNO_Alpha is used to identify the individual sample. We care about each sample over the individual crab, and thus will use SPNO_Alpha as the key. However, not all tables have a fully-developed SPNO_Alpha column. In the plate.dat and comments.dat tables, only crabs with multiple samples have an SPNO_Alpha, and the collection.data lacks the column altogether (as each row is one crab, not one sample)

First, we'll fill the SPNO_Alpha columns where appropriate.

Then, we'll check for duplicated or NA SPNO_Alpha or SPNO columns (depending on table)

First, we want to check to see that the SPNO values can, in fact, be used as unique crab identifiers. We also want to see whether (and how many) values are present in the plates.dat and comments.dat tables that are missing from the collection.dat table (since that'll be our base table). Finally, we'll check whether all our collection.dat values are present in the samp.dat table

```{r}
# Replace NA values in SPNO_Alpha column with the SPNO for comments.dat and plate.dat
comments.dat$SPNO_Alpha <- ifelse(is.na(comments.dat$SPNO_Alpha), comments.dat$SPNO, comments.dat$SPNO_Alpha)

plate.dat$SPNO_Alpha <- ifelse(is.na(plate.dat$SPNO_Alpha),
                               plate.dat$SPNO, plate.dat$SPNO_Alpha)

# Check for NA values in our tables
sum(is.na(collection.dat$SPNO))
sum(is.na(comments.dat$SPNO_Alpha))
sum(is.na(plate.dat$SPNO_Alpha))
sum(is.na(samp.dat$SPNO_Alpha))

# Check for duplicated values in our tables
any(duplicated(collection.dat$SPNO))
any(duplicated(comments.dat$SPNO_Alpha))
any(duplicated(plate.dat$SPNO_Alpha))
any(duplicated(samp.dat$SPNO_Alpha))

# Okay, looks we have no NAs or duplicates in our key columns - they're all unique and all have entries!

# We can perform left joins on these tables, with samp.dat as the base table. But first, let's verify values aren't missing from that samp.dat table

all(plate.dat$SPNO_Alpha %in% samp.dat$SPNO_Alpha)
all(comments.dat$SPNO_Alpha %in% samp.dat$SPNO_Alpha)
all(collection.dat$SPNO %in% samp.dat$SPNO)

# All good on plate.dat, but there are comments.dat and collection.dat values that aren't in samp.dat. Let's examine these

collection.dat[!collection.dat$SPNO %in% samp.dat$SPNO, ]

# For collection.dat, it's just two rows, one with an unknown species and the other apparently with an unknown year. We'll just drop that in our left join.

# Now let's look at our comments.dat table

comments.dat[!comments.dat$SPNO_Alpha %in% samp.dat$SPNO_Alpha, ]

# Okay, 7300 crabs have comments but no sample data. That's nearly half of the total crabs with comments, period!
# They probably won't be useful, since they don't have plate or collection data either (as all or nearly all crabs with plate or collection data are confirmed to have sample data), but better safe than sorry - we'll make that one a full join.
```

### Join tables together (Access)

Summary:
- Join samp.dat and collection.dat using SPNO. This will populate crabs with multiple SPNO_Alpha (i.e. crabs with multiple samples) with the same collection data.
- Join that table with plate.dat using SPNO_Alpha. This will add plate information to each sample.
- Join that table with comments.dat using SPNO_Alpha. This will add comments to each sample.


```{r}
# 1. Join samp.dat and collection.dat using SPNO
full.dat <- left_join(x = samp.dat, y = collection.dat, by = "SPNO")

# Check that we didn't add any rows
nrow(full.dat) == nrow(samp.dat)

# 2. Join full.dat and plate.dat
full.dat <- left_join(x = full.dat, y = plate.dat, by = "SPNO_Alpha")

# Check that we didn't add any rows
nrow(full.dat) == nrow(samp.dat)

# 3. Join that table with comments.dat
full.dat <- full_join(x = full.dat, y = comments.dat, by = "SPNO_Alpha")

# Checking that we're only adding the number of rows equal to unmatched comments as determined in the earlier chunk
nrow(samp.dat) + nrow(comments.dat[!comments.dat$SPNO_Alpha %in% samp.dat$SPNO_Alpha, ]) == nrow(full.dat)
```

### Removing Redundant Columns (Access)

Alright, we now have an extremely large data table - 92,000 rows and 63 columns! We want to reduce that quite substantially. We'll start off by reducing the number of columns present by eliminating fully-duplicated ones

```{r}
colnames(full.dat)

# Looks like we have three SPNO columns, plus an SPNO_Alpha and Alpha column. We can eliminate a few of these at least.
length(na.omit(full.dat$SPNO.x))
length(na.omit(full.dat$SPNO.y))
length(na.omit(full.dat$SPNO))

# When we merged samp.dat with plate.dat by SPNO_Alpha, the two columns turned to SPNO.x and SPNO.y, respectively. Then, the subsequent merge of comments.dat added the SPNO column. Therefore, we want to remove the SPNO.y and SPNO columns, as the SPNO.x (samp.dat) column contains all SPNO IDs in those two plus additional ones. We'll then rename SPNO.x to SPNO

full.dat <- select(full.dat, -c(SPNO.y, SPNO))
full.dat <- rename(full.dat, SPNO = SPNO.x)

# Look at colnames again
colnames(full.dat)

# Check the number of NA values per column
sapply(full.dat, function(y) sum(length(which(!is.na(y)))))

# Species_Name.x and Species_Name.y were created when we merged the samp.dat and comments.dat tables. We can remove Species_Name.y as it only contains info for crabs in comments.dat. We will then rename Species_Name.x to Species_Name
full.dat <- select(full.dat, -Species_Name.y)
full.dat <- rename(full.dat, Species_Name = Species_Name.x)

# Alright, we have a few additional duplicated columns - Collection Comments and Sample Comments each have one column from samp.dat and one from comments.dat. However, these don't necessarily contain entirely duplicated information, so we'll leave them for now. However, to avoid confusion, we'll rename

full.dat <- rename(full.dat, c(Sample_Comments = Sample_Comments.x, Collection_Comments = Collection_Comments.x, Addl_Collection_Comments = Collection_Comments.y, Addl_Sample_Comments = Sample_Comments.y))

# We will now write this to a table 
write.csv(full.dat, file = "../output/jensen_data/cleaned_data/accessdb_all_cols.csv", row.names = FALSE)
```

## Reading in Excel data (2014-2019)

Fantastic, we merged all our Access data! However, we still have a great deal of data that we still need to read in. The Access data only goes up through 2013. Everything 2014 and later is instead stored in separate Excel sheets. Those need to be read in individually. We'll do that now

We have data from the 2014-2019 NOAA EBS trawl surveys, along with data from the 2015 St. Matthew Island Blue King Crab survey.

The data collected on the 2015 SMI BKC survey will be formatted extremely differently, as it was a nonstandard collection, and the survey is a pot survey, while the EBS surveys are trawl surveys. Therefore, we won't even bother trying to read it in yet - we'll do that later. Instead, we'll first merge all EBS trawl survey data, and then try to merge that with the Access data

```{r}
# Get path to all files named above
excel.files <- Sys.glob(c("../data/jensen_archived_samples/jensen_data/Hemato_samples/data_2014-2019/*/201?_BCS_Index_Station_Collection_Data_MASTE*.xlsx"))

#### 2014 and 2015 EBS trawl data

# Read in 2014 data
recent.dat <- read_excel(excel.files[1], sheet = 2)

# Read in 2015 data
recent.dat2 <- read_excel(excel.files[2], sheet = 2)

# Check if column names are identical.
all(colnames(recent.dat) == colnames(recent.dat2))
# They aren't, so let's check which ones are different
colnames(recent.dat)[colnames(recent.dat) != colnames(recent.dat2)]
colnames(recent.dat2)[colnames(recent.dat) != colnames(recent.dat2)]

# Looks like the only differences are in capitalization and spacing - Chela = chela, and STATIONID = STATION ID.
# We'll rename the recent.dat column names, as the temporally recent one is more likely to be used for subsequent files
recent.dat <- rename(recent.dat, c("STATION ID" = STATIONID, chela = Chela))

# Verify all columns match 
all(colnames(recent.dat) == colnames(recent.dat2))

# We can now append the recent.dat2 file (the 2015 data) onto recent.dat (the 2014 data)
recent.dat <- bind_rows(recent.dat, recent.dat2)

#### 2016 EBS trawl data

# Read in file
recent.dat2 <- read_excel(excel.files[3], sheet = 2)

# Check if column names are identical
all(colnames(recent.dat) == colnames(recent.dat2))
# They aren't, so let's check which ones are different
colnames(recent.dat)[colnames(recent.dat) != colnames(recent.dat2)]
colnames(recent.dat2)[colnames(recent.dat) != colnames(recent.dat2)]

# Again, these are all differences in capitalization and spacing. PCR Result = PCR result, Host Tissue = Host_Tissue, and STATIONID = STATION ID
# We'll rename the recent.dat column names to the 2016 columns, as the temporally recent one is more likely to be used for subsequent files.
# Although as we just saw with STATIONID, that isn't necessarily true
recent.dat <- rename(recent.dat, c("PCR Result" = "PCR result", "Host Tissue" = Host_Tissue, STATIONID = "STATION ID"))

# Verify all columns match 
all(colnames(recent.dat) == colnames(recent.dat2))

# When we try to append the data file, we get a warning - the START TIME column in the 2016 data was read as a character, not a date
# Convert that column to date
recent.dat2$`START TIME` <-  mdy_hm(recent.dat2$`START TIME`)

# We can now append the recent.dat2 file (the 2016 data) onto recent.dat (the 2014-2015 data)
recent.dat <- bind_rows(recent.dat, recent.dat2)

#### 2017 EBS trawl data

# Read in file
recent.dat2 <- read_excel(excel.files[4], sheet = 2)

# Check if column names are identical
all(colnames(recent.dat) == colnames(recent.dat2))

# They aren't, so let's check which ones are different
colnames(recent.dat)[colnames(recent.dat) != colnames(recent.dat2)]
colnames(recent.dat2)[colnames(recent.dat) != colnames(recent.dat2)]

# Again, these are all differences in capitalization and spacing. PCR Result = PCR result
# We'll rename the recent.dat column names to the 2017 columns, as the temporally recent one is more likely to be used for subsequent files.
recent.dat <- rename(recent.dat, "PCR result" = "PCR Result")

# Verify all columns match 
all(colnames(recent.dat) == colnames(recent.dat2))

# We can now append the recent.dat2 file (the 2017 data) onto recent.dat (the 2014-2016 data)
recent.dat <- bind_rows(recent.dat, recent.dat2)

#### 2018 EBS trawl data

# Read in file
recent.dat2 <- read_excel(excel.files[5], sheet = 2)

# Looks like we have an extra 5 columns. Verify
ncol(recent.dat2) - ncol(recent.dat)

# Let's do a quick look to see if we can spot the differences
colnames(recent.dat)
colnames(recent.dat2)

# We sure can! The 2018 file has 5 extra columns related to maturity, as measured through the carapace width/chela height ratio. They are as follows:
# - ln(CW)
# - meas'd ln(Ch)
# - calc ln(Ch)
# - mat
# - Mat1

# We will remove all these columns and then check to see if column names match

recent.dat2 <- select(recent.dat2, -c("ln(CW)", "meas'd ln(Ch)", "calc ln(Ch)", mat, Mat1))

# Check if column names are now identical
all(colnames(recent.dat) == colnames(recent.dat2))

# They are, so we can now append the recent.dat2 file (the 2018 data) onto the recent.dat file (the 2014-2017 data)
recent.dat <- bind_rows(recent.dat, recent.dat2)

#### 2019 EBS trawl data

# Read in file
recent.dat2 <- read_excel(excel.files[6], sheet = 3)

# Looks like we have an extra 9 columns. Verify
ncol(recent.dat2) - ncol(recent.dat)

# Let's do a quick look to see if we can spot the differences
colnames(recent.dat)
colnames(recent.dat2)

# Again, we can. Six of the nine are related to determining maturity as before, while a look at the original Excel file shows that the final three are summary tables that can be deleted. The columns are as follows:
# MATURITY COLUMNS:
# - ln CW
# - measured ln (ChHt)
# - OLD solved ChHt
# - new cut line LN(Ch)
# - new cut line mat
# - new cut line 1
# SUMMARY TABLES:
# - ...43
# - ...44
# - ...45
# Remove all 9 of these columns
recent.dat2 <- select(recent.dat2, -c("ln CW", "measured ln (ChHt)", "OLD solved ChHt", 
                                      "new cut line LN(Ch)", "new cut line mat", "new cut line 1",
                                      "...43", "...44", "...45"))

# Check if column names are now identical
all(colnames(recent.dat) == colnames(recent.dat2))

# They aren't, let's see where they differ
colnames(recent.dat)[colnames(recent.dat) != colnames(recent.dat2)]
colnames(recent.dat2)[colnames(recent.dat) != colnames(recent.dat2)]

# Again, these are superficial changes in capitalization. VESSEL = Vessel, HAUL = haul
# This time, we'll change the column names for the 2019 data (recent.dat2)
recent.dat2 <- rename(recent.dat2, c(VESSEL = Vessel, HAUL = Haul))

# Check again if column names are identical
all(colnames(recent.dat) == colnames(recent.dat2))

# Nice! We'll now append the recent.dat2 file (the 2019 data) onto the recent.dat file (the 2014-2018 data)
recent.dat <- bind_rows(recent.dat, recent.dat2)

#### Small Data Corrections

# We will now change all column names with spaces
colnames(recent.dat) <- gsub(" ", "_", colnames(recent.dat))

# See if any rows don't have a unique SPNO
recent.dat[duplicated(recent.dat), ]
# Yep, we have four. All have NAs for practically all rows
recent.dat <- recent.dat[unique(recent.dat$SPNO), ]

# We will now write this to a table 
write.csv(recent.dat, file = "../output/jensen_data/cleaned_data/excel_ebs_data_all_cols.csv", row.names = FALSE)
```

### Merging Access and Excel Data (EBS Trawl)

We'll now try to merge the data from the Access databases and the EBS Trawl Excel sheets (2014-2019).

Since the formatting is extremely different, we will NOT try to merge the 2015 SMI BKC survey data. We'll work on that a bit later - at this stage, we haven't even read it in.

There are a lot of differences in column names and which variables were tracked. I will try to map as many as possible to each other

| Access_Data_variable       | EBS_Excel_Data_variable     |
|----------------------------|-----------------------------|
| SPNO                       | SPNO                        |
| Alpha                      |                             |
| Host_OR_Parasite           |                             |
| Host_Tissue                | Host_Tissue                 |
| Taxon_Removed              |                             |
| Parasite_Species           |                             |
| Parasite_Most_Recent_ID_By |                             |
| Sample_Type                |                             |
| Preservative               | Preservative                |
| Protocol                   |                             |
| Sample_Status              | Sample_Status               |
| Sample_Comments            |                             |
| SPNO_Alpha                 |                             |
| Species_Name               | Species_Name                |
| Sex                        | Sex                         |
| Size                       | Size                        |
| Chela                      | chela                       |
| Shell_Condition            | Shell_Cond                  |
| Clutch                     | Clutch                      |
| Random                     | Random                      |
| Collection_Comments        | Collection_Comments         |
| BODYID                     |                             |
| VISUAL                     | ANOM_ID                     |
| DISTID                     |                             |
| Year                       | Year                        |
| Date                       | START_TIME [1 of 2 matches] |
| HISTO_result               |                             |
| SMEAR_result               |                             |
| T_Rating                   |                             |
| BCS_PCR_results            | PCR_result                  |
| Specific_Location          | Specific_Location           |
| General_Location           | General_Location            |
| Collected_By               | Collected_By                |
| Most_Recent_ID_By          |                             |
| ReferenceNO                | Reference_NO                |
| C_V_H                      | C_V_H                       |
| Cruise                     | CRUISE                      |
| Vessel                     | VESSEL                      |
| Haul                       | HAUL                        |
| StationID                  | STATIONID                   |
| Stratum                    | STRATUM                     |
| LME                        |                             |
| Bering_Sea_Regions         |                             |
| Haul_Date                  | START_TIME [1 of 2 matches] |
| Latitude                   | START_LATITUDE              |
| Longitude                  | START_LONGITUDE             |
| Depth                      | BOTTOM_DEPTH                |
| Bottom_Type                |                             |
| Bottom_Temp                | Bottom_Temp                 |
| Surface_Temp               | SURFACE_TEMP                |
| Haul_Comments              |                             |
| Category1                  |                             |
| Category2                  |                             |
| Category3                  |                             |
| Category4                  |                             |
| Category5_decapods         |                             |
| Plate                      | DNA_Plate_No                |
| Plate_Comments             |                             |
| Addl_Collection_Comments   |                             |
| Addl_Sample_Comments       |                             |
|                            | Egg_Color                   |
|                            | Egg_Cond                    |
|                            | DNA_Well_No                 |
|                            | GEAR_DEPTH                  |



```{r}
# Duplicate date column in recent.dat to create a Haul_Date column
recent.dat$Haul_Date <- recent.dat$START_TIME


# Rename columns in EBS Excel data to match column names in Access data
recent.dat <- rename(recent.dat, c(Chela = chela,
                             Shell_Condition = Shell_Cond,
                             VISUAL = ANOM_ID,
                             Date = START_TIME,
                             BCS_PCR_results = PCR_result,
                             ReferenceNO = Reference_NO,
                             Cruise = CRUISE,
                             Vessel = VESSEL,
                             Haul = HAUL,
                             StationID = STATIONID,
                             Stratum = STRATUM,
                             Latitude = START_LATITUDE,
                             Longitude = START_LONGITUDE,
                             Depth = BOTTOM_DEPTH,
                             Surface_Temp = SURFACE_TEMP,
                             Plate = DNA_Plate_No))

# If we try to bind here, we get an error, as full.dat$VISUAL is a character column, while recent.dat$VISUAL is a double.
# This is also the case for Plate
# Change recent.dat$VISUAL to a character
recent.dat$VISUAL <- as.character(recent.dat$VISUAL)
recent.dat$Plate <- as.character(recent.dat$Plate)

# Bind rows from Excel data to Access data
full.dat <- bind_rows(full.dat, recent.dat)

# Excellent, we have 99,419 rows and 64 columns.
# Rows are equal to the 92,332 in the Access data plus the 7087 in the Excel EBS data
# Columns are equal to the 60 in the Access data plus the 4 unique to the Excel EBS data
```

### Read in St. Matthew Island 2015 data

So far, we've merged data from two formats - the Access database for data prior to 2013, and the Excel database for EBS data from 2014-2019. 

We only have one data format left - the 2015 St. Matthew Island Blue King Crab survey. We'll read that in, and then merge columns

```{r}
# Set path to file folder
excel_path <- "../data/jensen_archived_samples/jensen_data/Hemato_samples/data_2014-2019/2015_StMatt/"

#### Results Data

SMI.results.dat <- read_excel(paste0(excel_path, "2015_St_Matt_results.xlsx"), sheet = 1, skip = 3)

# Remove columns that are artifacts of weird data entry format from results data
SMI.results.dat <- select(SMI.results.dat, -c("...4", "Prevalence:",
                                              "...6", "...10",
                                              "...13", "Plate 2015-44"))

# Shape data table to widen columns
SMI.results.dat <- data.frame("SPNO" = c(SMI.results.dat$...1, SMI.results.dat$SPNO, SMI.results.dat$`Tag #`),
                              "Well" = c(SMI.results.dat$Well...2, SMI.results.dat$Well...8, rep(NA, times = length(SMI.results.dat$`Tag #`))),
                              "PCR_result" = c(SMI.results.dat$`PCR result...3`, SMI.results.dat$`PCR result...9`, SMI.results.dat$`PCR result...12`))

# Remove all rows consisting of only NAs
SMI.results.dat <- SMI.results.dat[rowSums(is.na(SMI.results.dat)) != ncol(SMI.results.dat), ]

# Within our SPNO column, we have some SPNO listed as 2###-4###, and others as 2### / 4####. We want all to take the first format, so let's change that " / " to a "-"
SMI.results.dat$SPNO <- gsub(" / ", "-", SMI.results.dat$SPNO)

# Separate 2### and 4### portions of SPNO column
SMI.results.dat <- separate(SMI.results.dat, col = SPNO, into = c("ident_num", "ID"), sep = "-")

# That 4### portion is the tray number + the well number. So Tray 42, Well 3 would be 4003
SMI.results.dat <- separate(SMI.results.dat, col = ID, into = c("Tray", "Well_Num"), sep = 2)

#### Main data

# We have two data tables. It seems that some random samples were taken (labeled with the prefix 2015 in the original SPNO column of SMI.results.dat), and other crabs were selected because they appeared to be BCS positive. These were tagged, and labeled with the tag number as their prefix in that SPNO column. Therefore, we need to read in and merge both data tables.

# The crabs that were selected due to an apparent BCS positive appearance were likely transported live back to Kodiak for sampling and testing, while others were sampled on the spot.

# Read in seemingly-random sample data
SMI.dat <- read_excel(paste0(excel_path, "ADFG_2015_St_Matt_SnowCrab_BCS_Data_for_NMFS-Pam_Jensen.xlsx"), 
                             sheet = 2, skip = 1)
# Read in selected sample data
SMI.selected.dat <- read_excel(paste0(excel_path, "ADFG_2015_St_Matt_SnowCrab_BCS_Data_for_NMFS-Pam_Jensen.xlsx"), 
                             sheet = 1, skip = 1)

# Check to see which column names are in SMI.selected.dat, but not SMI.dat
colnames(SMI.dat)[!colnames(SMI.dat) %in% colnames(SMI.selected.dat)]
# And check to see the reverse - which are in SMI.dat, but not SMI.selected.dat
colnames(SMI.selected.dat)[!colnames(SMI.selected.dat) %in% colnames(SMI.dat)]

# Two of these, carapace width and chela height, are the result of minor differences in column names. Here's a quick explanation of the ones that aren't.
# UNIQUE TO SMI.dat
# Shell_Condition: Same as usual, the age of the shell. Possibly not taken in visibly-infected crabs, as the "bleaching" effects of Hematodinium make it difficult to judge
# Signs_of_BCS: Presumably positive for all visibly-infected crabs
# 
# UNIQUE TO SMI.selected.dat
# SPN (sequential pot number). Each survey begins at SPN = 1, and runs sequentially. Generally, there are 4 pots per station.
# BCS_Tag_Num: As speculated above, these crabs were likely kept live and transported, and therefore each needed a tag
# Removed_Dead: Some crabs likely died en route or during the survey, and thus their death date was marked
# Comments: Simply not present for the ones sampled on survey randomly, likely because unusual crab were intentionally not sampled.

# Rename carapace width and chela height to match the conventions in SMI.dat
SMI.selected.dat <- rename(SMI.selected.dat, c(Carapace_Width = Carapace_Width_mm, 
                                   Chela_Height = Chela_Height_mm))

# We'll also change the Station column to a character for SMI.selected.dat
SMI.selected.dat$Station <- as.character(SMI.selected.dat$Station)


# We will now append the two data tables. Columns not present in the other table will be filled with NAs
SMI.dat <- bind_rows(SMI.dat, SMI.selected.dat, .id = "ADFG_ID")

# Remove the newly-created ADFG_ID ID
SMI.dat <- select(SMI.dat, -"ADFG_ID")

#### Binding Survey Data and PCR Data

# We will now bind the SMI.dat table we just created, which contains all collection data, with the SMI.results.dat table, which contains the PCR results

# Convert SMI.dat$Tray to character
SMI.dat$Tray <- as.character(SMI.dat$Tray)

SMI.dat <- left_join(SMI.dat, SMI.results.dat, by = c("Tray", "Well"))

# We will now change all column names with spaces
colnames(SMI.dat) <- gsub(" ", "_", colnames(SMI.dat))

# We also want to remove redundant columns. We have three for each of depth, temp, and salinity - a min, a max, and an average. We'll remove the min and max columns for each.
SMI.dat <- select(SMI.dat, -c(Min_depth_m, Max_depth_m,
                              "Min_temp_C°", "Max_temp_C°",
                              Min_salinity_PSU, Max_salinity_PSU))

# Our temperature column also has a nonstandard name (contains the degree symbol), so we'll remove that symbol
SMI.dat <- rename(SMI.dat, Avg_temp_C = "Avg_temp_C°")

# Some crabs have a Well value, but no Well_Num. If we look at other samples, it is evident that wells were numbered beginning at A1 and continuing vertically (e.g. A1 = 1, B1 = 2... H1 = 8, A2 = 9). Therefore, we can convert the Well values to give us a Well_Num
# We'll do this inside a for loop

for (i in 1:nrow(SMI.dat)) {
  well_val <- SMI.dat$Well[i]
  numb <- gsub("[^[:digit:]]", "", well_val)
  lett <- gsub("[[:digit:]]", "", well_val)
  num <- (as.numeric(numb) - 1) * 8 + match(lett, LETTERS[1:26])
  SMI.dat$Well_Num[i] <- num
}


# We now want to pad this well_num value so it always equals two digits
SMI.dat$Well_Num <- str_pad(SMI.dat$Well_Num, 2, pad = 0)

# Create SPNO column. The format for this is generally YYYYPPWW, with PP = plate number, and WW = well number (and YYYY = year). However, this could create overlaps with the regular 2015 EBS survey, so we'll precede this with "SMI_". Some crabs have NAs for plate and well numbers. These will instead be given an SPNO equal to their ADFG_ID preceded by SMI_.

# Create a blank column for SPNO that we'll fill
SMI.dat$SPNO <- rep("blank", times = nrow(SMI.dat))

# Check if any crabs have an NA for plate, but not well numbers, and vice-versa
SMI.dat[is.na(SMI.dat$Tray) & !is.na(SMI.dat$Well_Num), ]
SMI.dat[!is.na(SMI.dat$Tray) & is.na(SMI.dat$Well_Num), ]

# Excellent. We'll assign crabs with NAs for both plate and well numbers an SPNO equal to their ADFG_ID, as described above.
# We'll work on adding the preceding SMI_ later
SMI.dat[is.na(SMI.dat$Tray) & is.na(SMI.dat$Well_Num), ]$SPNO <- SMI.dat[is.na(SMI.dat$Tray) & is.na(SMI.dat$Well_Num), ]$ADFG_ID

# Now assign all other crabs a standard SPNO, as described above
SMI.dat[!is.na(SMI.dat$Tray) & !is.na(SMI.dat$Well_Num), ]$SPNO <- paste0(2015, 
                                                                          SMI.dat[!is.na(SMI.dat$Tray) & !is.na(SMI.dat$Well_Num), ]$Tray,
                                                                          SMI.dat[!is.na(SMI.dat$Tray) & !is.na(SMI.dat$Well_Num), ]$Well_Num)
  
# Beautiful! We now want to preface all SPNO values with "SMI_"
SMI.dat$SPNO <- paste0("SMI_", SMI.dat$SPNO)

# Check SPNO values for duplicates
SMI.dat[duplicated(SMI.dat$SPNO), ]
```

Alright, we want to now merge our St. Matthew Island data with the combined Access/Excel data. We'll rename the columns to map as many as possible to each other. The SMI.dat columns will be renamed to match the Access/Excel data columns. Here's a table of the columns:

```{r}
# We'll also create extra columns for Year,
SMI.dat$Year <- "2015"


```






### Cleaning

In the chunk above, we ONLY removed data that had been completely duplicated, giving us a full and complete data table. In the next chunk, we'll be a bit more aggressive, removing rows and columns that don't provide useful information on the specific plate samples that we have. 


```{r}
colnames(full.dat)

# First, we'll remove all rows without a plate ID
full.plate.dat <- full.dat[!is.na(full.dat$Plate), ]

# Now we'll get the number of non-NA values per column
sapply(full.plate.dat, function(y) sum(length(which(!is.na(y)))))

# Alright, we can safely remove the following columns, as they have no non-NA values
# Taxon_Removed
# Parasite_Species
# Parasite_Most_Recent_ID_By
# DISTID
# Most_Recent_ID_By

full.plate.dat <- select(full.plate.dat, -c(Taxon_Removed, Parasite_Species, Parasite_Most_Recent_ID_By, DISTID, Most_Recent_ID_By))

# We also have some comments that likely contain minimal information
table(full.plate.dat$Category1)
table(full.plate.dat$Category2)
table(full.plate.dat$Category3)
table(full.plate.dat$Category4)
table(full.plate.dat$Category5_decapods)
sum(is.na(full.plate.dat$Species_Name))

# All rows have a given species name. Therefore, the specific taxonomic identity is irrelevant - we don't have such a large number of species that it'd be useful. Plus, every row is identical for Categories 1-3. Therefore, drop Category1-5 columns
full.plate.dat <- select(full.plate.dat, -c(Category1, Category2, Category3, Category4, Category5_decapods))

table(full.plate.dat$Host_OR_Parasite)
sum(is.na(full.plate.dat$Host_OR_Parasite))
# In the Host_OR_Parasite column, all rows contain some variant of "Host Tissue". Therefore, we can remove the column
full.plate.dat <- select(full.plate.dat, -Host_OR_Parasite)

table(full.plate.dat$Sample_Type)
# All rows are DNA samples, remove
full.plate.dat <- select(full.plate.dat, -Sample_Type)

# Remove samples that are designated as Used Up/Thrown Out/unavailable
table(full.plate.dat$Sample_Status)
full.plate.dat <- full.plate.dat[full.plate.dat$Sample_Status != "Used Up/Thrown Out/unavailable", ]

# We can now remove the Sample Status column, as all samples are either "available" or "To Roberts lab", both of which mean they could be in our possession
full.plate.dat <- select(full.plate.dat, -Sample_Status)


```






